# coding: utf-8

"""
    Cloud Speech-to-Text API

    Converts audio to text by applying powerful neural network models. <br> **PLEASE NOTE**: This API is provided by Google, beside the documentation provide below, you can find Google API documentation [here](https://cloud.google.com/speech-to-text/docs/reference/rest). You can refer to the Google documentation as well except by the URLs needed to call the API and that are documented here below.  # noqa: E501

    OpenAPI spec version: v3.3
    
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""

import pprint
import re  # noqa: F401

import six


class RecognitionConfig(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    """
    """
    Attributes:
      swagger_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    swagger_types = {
        'encoding': 'str',
        'speech_contexts': 'list[SpeechContext]',
        'model': 'str',
        'audio_channel_count': 'int',
        'diarization_config': 'SpeakerDiarizationConfig',
        'enable_word_time_offsets': 'bool',
        'language_code': 'str',
        'profanity_filter': 'bool',
        'use_enhanced': 'bool',
        'metadata': 'RecognitionMetadata',
        'sample_rate_hertz': 'int',
        'enable_separate_recognition_per_channel': 'bool',
        'enable_automatic_punctuation': 'bool',
        'max_alternatives': 'int'
    }

    attribute_map = {
        'encoding': 'encoding',
        'speech_contexts': 'speechContexts',
        'model': 'model',
        'audio_channel_count': 'audioChannelCount',
        'diarization_config': 'diarizationConfig',
        'enable_word_time_offsets': 'enableWordTimeOffsets',
        'language_code': 'languageCode',
        'profanity_filter': 'profanityFilter',
        'use_enhanced': 'useEnhanced',
        'metadata': 'metadata',
        'sample_rate_hertz': 'sampleRateHertz',
        'enable_separate_recognition_per_channel': 'enableSeparateRecognitionPerChannel',
        'enable_automatic_punctuation': 'enableAutomaticPunctuation',
        'max_alternatives': 'maxAlternatives'
    }

    def __init__(self, encoding=None, speech_contexts=None, model=None, audio_channel_count=None, diarization_config=None, enable_word_time_offsets=None, language_code=None, profanity_filter=None, use_enhanced=None, metadata=None, sample_rate_hertz=None, enable_separate_recognition_per_channel=None, enable_automatic_punctuation=None, max_alternatives=None):  # noqa: E501
        """RecognitionConfig - a model defined in Swagger"""  # noqa: E501
        self._encoding = None
        self._speech_contexts = None
        self._model = None
        self._audio_channel_count = None
        self._diarization_config = None
        self._enable_word_time_offsets = None
        self._language_code = None
        self._profanity_filter = None
        self._use_enhanced = None
        self._metadata = None
        self._sample_rate_hertz = None
        self._enable_separate_recognition_per_channel = None
        self._enable_automatic_punctuation = None
        self._max_alternatives = None
        self.discriminator = None
        if encoding is not None:
            self.encoding = encoding
        if speech_contexts is not None:
            self.speech_contexts = speech_contexts
        if model is not None:
            self.model = model
        if audio_channel_count is not None:
            self.audio_channel_count = audio_channel_count
        if diarization_config is not None:
            self.diarization_config = diarization_config
        if enable_word_time_offsets is not None:
            self.enable_word_time_offsets = enable_word_time_offsets
        if language_code is not None:
            self.language_code = language_code
        if profanity_filter is not None:
            self.profanity_filter = profanity_filter
        if use_enhanced is not None:
            self.use_enhanced = use_enhanced
        if metadata is not None:
            self.metadata = metadata
        if sample_rate_hertz is not None:
            self.sample_rate_hertz = sample_rate_hertz
        if enable_separate_recognition_per_channel is not None:
            self.enable_separate_recognition_per_channel = enable_separate_recognition_per_channel
        if enable_automatic_punctuation is not None:
            self.enable_automatic_punctuation = enable_automatic_punctuation
        if max_alternatives is not None:
            self.max_alternatives = max_alternatives

    @property
    def encoding(self):
        """Gets the encoding of this RecognitionConfig.  # noqa: E501

        Encoding of audio data sent in all `RecognitionAudio` messages. This field is optional for `FLAC` and `WAV` audio files and required for all other audio formats. For details, see AudioEncoding.  # noqa: E501

        :return: The encoding of this RecognitionConfig.  # noqa: E501
        :rtype: str
        """
        return self._encoding

    @encoding.setter
    def encoding(self, encoding):
        """Sets the encoding of this RecognitionConfig.

        Encoding of audio data sent in all `RecognitionAudio` messages. This field is optional for `FLAC` and `WAV` audio files and required for all other audio formats. For details, see AudioEncoding.  # noqa: E501

        :param encoding: The encoding of this RecognitionConfig.  # noqa: E501
        :type: str
        """
        allowed_values = ["ENCODING_UNSPECIFIED", "LINEAR16", "FLAC", "MULAW", "AMR", "AMR_WB", "OGG_OPUS", "SPEEX_WITH_HEADER_BYTE"]  # noqa: E501
        if encoding not in allowed_values:
            raise ValueError(
                "Invalid value for `encoding` ({0}), must be one of {1}"  # noqa: E501
                .format(encoding, allowed_values)
            )

        self._encoding = encoding

    @property
    def speech_contexts(self):
        """Gets the speech_contexts of this RecognitionConfig.  # noqa: E501

        Array of SpeechContext. A means to provide context to assist the speech recognition. For more information, see [speech adaptation](https://cloud.google.com/speech-to-text/docs/context-strength).  # noqa: E501

        :return: The speech_contexts of this RecognitionConfig.  # noqa: E501
        :rtype: list[SpeechContext]
        """
        return self._speech_contexts

    @speech_contexts.setter
    def speech_contexts(self, speech_contexts):
        """Sets the speech_contexts of this RecognitionConfig.

        Array of SpeechContext. A means to provide context to assist the speech recognition. For more information, see [speech adaptation](https://cloud.google.com/speech-to-text/docs/context-strength).  # noqa: E501

        :param speech_contexts: The speech_contexts of this RecognitionConfig.  # noqa: E501
        :type: list[SpeechContext]
        """

        self._speech_contexts = speech_contexts

    @property
    def model(self):
        """Gets the model of this RecognitionConfig.  # noqa: E501

        Which model to select for the given request. Select the model best suited to your domain to get best results. If a model is not explicitly specified, then we auto-select a model based on the parameters in the RecognitionConfig. <table>   <tr>     <td><b>Model</b></td>     <td><b>Description</b></td>   </tr>   <tr>     <td><code>command_and_search</code></td>     <td>Best for short queries such as voice commands or voice search.</td>   </tr>   <tr>     <td><code>phone_call</code></td>     <td>Best for audio that originated from a phone call (typically     recorded at an 8khz sampling rate).</td>   </tr>   <tr>     <td><code>video</code></td>     <td>Best for audio that originated from from video or includes multiple         speakers. Ideally the audio is recorded at a 16khz or greater         sampling rate. This is a premium model that costs more than the         standard rate.</td>   </tr>   <tr>     <td><code>default</code></td>     <td>Best for audio that is not one of the specific audio models.         For example, long-form audio. Ideally the audio is high-fidelity,         recorded at a 16khz or greater sampling rate.</td>   </tr> </table>  # noqa: E501

        :return: The model of this RecognitionConfig.  # noqa: E501
        :rtype: str
        """
        return self._model

    @model.setter
    def model(self, model):
        """Sets the model of this RecognitionConfig.

        Which model to select for the given request. Select the model best suited to your domain to get best results. If a model is not explicitly specified, then we auto-select a model based on the parameters in the RecognitionConfig. <table>   <tr>     <td><b>Model</b></td>     <td><b>Description</b></td>   </tr>   <tr>     <td><code>command_and_search</code></td>     <td>Best for short queries such as voice commands or voice search.</td>   </tr>   <tr>     <td><code>phone_call</code></td>     <td>Best for audio that originated from a phone call (typically     recorded at an 8khz sampling rate).</td>   </tr>   <tr>     <td><code>video</code></td>     <td>Best for audio that originated from from video or includes multiple         speakers. Ideally the audio is recorded at a 16khz or greater         sampling rate. This is a premium model that costs more than the         standard rate.</td>   </tr>   <tr>     <td><code>default</code></td>     <td>Best for audio that is not one of the specific audio models.         For example, long-form audio. Ideally the audio is high-fidelity,         recorded at a 16khz or greater sampling rate.</td>   </tr> </table>  # noqa: E501

        :param model: The model of this RecognitionConfig.  # noqa: E501
        :type: str
        """

        self._model = model

    @property
    def audio_channel_count(self):
        """Gets the audio_channel_count of this RecognitionConfig.  # noqa: E501

        The number of channels in the input audio data. ONLY set this for MULTI-CHANNEL recognition. Valid values for LINEAR16 and FLAC are `1`-`8`. Valid values for OGG_OPUS are '1'-'254'. Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only `1`. If `0` or omitted, defaults to one channel (mono). Note: We only recognize the first channel by default. To perform independent recognition on each channel set `enable_separate_recognition_per_channel` to 'true'.  # noqa: E501

        :return: The audio_channel_count of this RecognitionConfig.  # noqa: E501
        :rtype: int
        """
        return self._audio_channel_count

    @audio_channel_count.setter
    def audio_channel_count(self, audio_channel_count):
        """Sets the audio_channel_count of this RecognitionConfig.

        The number of channels in the input audio data. ONLY set this for MULTI-CHANNEL recognition. Valid values for LINEAR16 and FLAC are `1`-`8`. Valid values for OGG_OPUS are '1'-'254'. Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only `1`. If `0` or omitted, defaults to one channel (mono). Note: We only recognize the first channel by default. To perform independent recognition on each channel set `enable_separate_recognition_per_channel` to 'true'.  # noqa: E501

        :param audio_channel_count: The audio_channel_count of this RecognitionConfig.  # noqa: E501
        :type: int
        """

        self._audio_channel_count = audio_channel_count

    @property
    def diarization_config(self):
        """Gets the diarization_config of this RecognitionConfig.  # noqa: E501


        :return: The diarization_config of this RecognitionConfig.  # noqa: E501
        :rtype: SpeakerDiarizationConfig
        """
        return self._diarization_config

    @diarization_config.setter
    def diarization_config(self, diarization_config):
        """Sets the diarization_config of this RecognitionConfig.


        :param diarization_config: The diarization_config of this RecognitionConfig.  # noqa: E501
        :type: SpeakerDiarizationConfig
        """

        self._diarization_config = diarization_config

    @property
    def enable_word_time_offsets(self):
        """Gets the enable_word_time_offsets of this RecognitionConfig.  # noqa: E501

        If `true`, the top result includes a list of words and the start and end time offsets (timestamps) for those words. If `false`, no word-level time offset information is returned. The default is `false`.  # noqa: E501

        :return: The enable_word_time_offsets of this RecognitionConfig.  # noqa: E501
        :rtype: bool
        """
        return self._enable_word_time_offsets

    @enable_word_time_offsets.setter
    def enable_word_time_offsets(self, enable_word_time_offsets):
        """Sets the enable_word_time_offsets of this RecognitionConfig.

        If `true`, the top result includes a list of words and the start and end time offsets (timestamps) for those words. If `false`, no word-level time offset information is returned. The default is `false`.  # noqa: E501

        :param enable_word_time_offsets: The enable_word_time_offsets of this RecognitionConfig.  # noqa: E501
        :type: bool
        """

        self._enable_word_time_offsets = enable_word_time_offsets

    @property
    def language_code(self):
        """Gets the language_code of this RecognitionConfig.  # noqa: E501

        Required. The language of the supplied audio as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: \"en-US\". See [Language Support](https://cloud.google.com/speech-to-text/docs/languages) for a list of the currently supported language codes.  # noqa: E501

        :return: The language_code of this RecognitionConfig.  # noqa: E501
        :rtype: str
        """
        return self._language_code

    @language_code.setter
    def language_code(self, language_code):
        """Sets the language_code of this RecognitionConfig.

        Required. The language of the supplied audio as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: \"en-US\". See [Language Support](https://cloud.google.com/speech-to-text/docs/languages) for a list of the currently supported language codes.  # noqa: E501

        :param language_code: The language_code of this RecognitionConfig.  # noqa: E501
        :type: str
        """

        self._language_code = language_code

    @property
    def profanity_filter(self):
        """Gets the profanity_filter of this RecognitionConfig.  # noqa: E501

        If set to `true`, the server will attempt to filter out profanities, replacing all but the initial character in each filtered word with asterisks, e.g. \"f***\". If set to `false` or omitted, profanities won't be filtered out.  # noqa: E501

        :return: The profanity_filter of this RecognitionConfig.  # noqa: E501
        :rtype: bool
        """
        return self._profanity_filter

    @profanity_filter.setter
    def profanity_filter(self, profanity_filter):
        """Sets the profanity_filter of this RecognitionConfig.

        If set to `true`, the server will attempt to filter out profanities, replacing all but the initial character in each filtered word with asterisks, e.g. \"f***\". If set to `false` or omitted, profanities won't be filtered out.  # noqa: E501

        :param profanity_filter: The profanity_filter of this RecognitionConfig.  # noqa: E501
        :type: bool
        """

        self._profanity_filter = profanity_filter

    @property
    def use_enhanced(self):
        """Gets the use_enhanced of this RecognitionConfig.  # noqa: E501

        Set to true to use an enhanced model for speech recognition. If `use_enhanced` is set to true and the `model` field is not set, then an appropriate enhanced model is chosen if an enhanced model exists for the audio.  If `use_enhanced` is true and an enhanced version of the specified model does not exist, then the speech is recognized using the standard version of the specified model.  # noqa: E501

        :return: The use_enhanced of this RecognitionConfig.  # noqa: E501
        :rtype: bool
        """
        return self._use_enhanced

    @use_enhanced.setter
    def use_enhanced(self, use_enhanced):
        """Sets the use_enhanced of this RecognitionConfig.

        Set to true to use an enhanced model for speech recognition. If `use_enhanced` is set to true and the `model` field is not set, then an appropriate enhanced model is chosen if an enhanced model exists for the audio.  If `use_enhanced` is true and an enhanced version of the specified model does not exist, then the speech is recognized using the standard version of the specified model.  # noqa: E501

        :param use_enhanced: The use_enhanced of this RecognitionConfig.  # noqa: E501
        :type: bool
        """

        self._use_enhanced = use_enhanced

    @property
    def metadata(self):
        """Gets the metadata of this RecognitionConfig.  # noqa: E501


        :return: The metadata of this RecognitionConfig.  # noqa: E501
        :rtype: RecognitionMetadata
        """
        return self._metadata

    @metadata.setter
    def metadata(self, metadata):
        """Sets the metadata of this RecognitionConfig.


        :param metadata: The metadata of this RecognitionConfig.  # noqa: E501
        :type: RecognitionMetadata
        """

        self._metadata = metadata

    @property
    def sample_rate_hertz(self):
        """Gets the sample_rate_hertz of this RecognitionConfig.  # noqa: E501

        Sample rate in Hertz of the audio data sent in all `RecognitionAudio` messages. Valid values are: 8000-48000. 16000 is optimal. For best results, set the sampling rate of the audio source to 16000 Hz. If that's not possible, use the native sample rate of the audio source (instead of re-sampling). This field is optional for FLAC and WAV audio files, but is required for all other audio formats. For details, see AudioEncoding.  # noqa: E501

        :return: The sample_rate_hertz of this RecognitionConfig.  # noqa: E501
        :rtype: int
        """
        return self._sample_rate_hertz

    @sample_rate_hertz.setter
    def sample_rate_hertz(self, sample_rate_hertz):
        """Sets the sample_rate_hertz of this RecognitionConfig.

        Sample rate in Hertz of the audio data sent in all `RecognitionAudio` messages. Valid values are: 8000-48000. 16000 is optimal. For best results, set the sampling rate of the audio source to 16000 Hz. If that's not possible, use the native sample rate of the audio source (instead of re-sampling). This field is optional for FLAC and WAV audio files, but is required for all other audio formats. For details, see AudioEncoding.  # noqa: E501

        :param sample_rate_hertz: The sample_rate_hertz of this RecognitionConfig.  # noqa: E501
        :type: int
        """

        self._sample_rate_hertz = sample_rate_hertz

    @property
    def enable_separate_recognition_per_channel(self):
        """Gets the enable_separate_recognition_per_channel of this RecognitionConfig.  # noqa: E501

        This needs to be set to `true` explicitly and `audio_channel_count` > 1 to get each channel recognized separately. The recognition result will contain a `channel_tag` field to state which channel that result belongs to. If this is not true, we will only recognize the first channel. The request is billed cumulatively for all channels recognized: `audio_channel_count` multiplied by the length of the audio.  # noqa: E501

        :return: The enable_separate_recognition_per_channel of this RecognitionConfig.  # noqa: E501
        :rtype: bool
        """
        return self._enable_separate_recognition_per_channel

    @enable_separate_recognition_per_channel.setter
    def enable_separate_recognition_per_channel(self, enable_separate_recognition_per_channel):
        """Sets the enable_separate_recognition_per_channel of this RecognitionConfig.

        This needs to be set to `true` explicitly and `audio_channel_count` > 1 to get each channel recognized separately. The recognition result will contain a `channel_tag` field to state which channel that result belongs to. If this is not true, we will only recognize the first channel. The request is billed cumulatively for all channels recognized: `audio_channel_count` multiplied by the length of the audio.  # noqa: E501

        :param enable_separate_recognition_per_channel: The enable_separate_recognition_per_channel of this RecognitionConfig.  # noqa: E501
        :type: bool
        """

        self._enable_separate_recognition_per_channel = enable_separate_recognition_per_channel

    @property
    def enable_automatic_punctuation(self):
        """Gets the enable_automatic_punctuation of this RecognitionConfig.  # noqa: E501

        If 'true', adds punctuation to recognition result hypotheses. This feature is only available in select languages. Setting this for requests in other languages has no effect at all. The default 'false' value does not add punctuation to result hypotheses. Note: This is currently offered as an experimental service, complimentary to all users. In the future this may be exclusively available as a premium feature.  # noqa: E501

        :return: The enable_automatic_punctuation of this RecognitionConfig.  # noqa: E501
        :rtype: bool
        """
        return self._enable_automatic_punctuation

    @enable_automatic_punctuation.setter
    def enable_automatic_punctuation(self, enable_automatic_punctuation):
        """Sets the enable_automatic_punctuation of this RecognitionConfig.

        If 'true', adds punctuation to recognition result hypotheses. This feature is only available in select languages. Setting this for requests in other languages has no effect at all. The default 'false' value does not add punctuation to result hypotheses. Note: This is currently offered as an experimental service, complimentary to all users. In the future this may be exclusively available as a premium feature.  # noqa: E501

        :param enable_automatic_punctuation: The enable_automatic_punctuation of this RecognitionConfig.  # noqa: E501
        :type: bool
        """

        self._enable_automatic_punctuation = enable_automatic_punctuation

    @property
    def max_alternatives(self):
        """Gets the max_alternatives of this RecognitionConfig.  # noqa: E501

        Maximum number of recognition hypotheses to be returned. Specifically, the maximum number of `SpeechRecognitionAlternative` messages within each `SpeechRecognitionResult`. The server may return fewer than `max_alternatives`. Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of one. If omitted, will return a maximum of one.  # noqa: E501

        :return: The max_alternatives of this RecognitionConfig.  # noqa: E501
        :rtype: int
        """
        return self._max_alternatives

    @max_alternatives.setter
    def max_alternatives(self, max_alternatives):
        """Sets the max_alternatives of this RecognitionConfig.

        Maximum number of recognition hypotheses to be returned. Specifically, the maximum number of `SpeechRecognitionAlternative` messages within each `SpeechRecognitionResult`. The server may return fewer than `max_alternatives`. Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of one. If omitted, will return a maximum of one.  # noqa: E501

        :param max_alternatives: The max_alternatives of this RecognitionConfig.  # noqa: E501
        :type: int
        """

        self._max_alternatives = max_alternatives

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.swagger_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value
        if issubclass(RecognitionConfig, dict):
            for key, value in self.items():
                result[key] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, RecognitionConfig):
            return False

        return self.__dict__ == other.__dict__

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        return not self == other
